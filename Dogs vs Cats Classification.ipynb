{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "724a2e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator,load_img\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b4d52b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Image_Width=128\n",
    "Image_Height=128\n",
    "Image_Size=(Image_Width,Image_Height)\n",
    "Image_Channels=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34265218",
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames=os.listdir(\"Resources/dogs-vs-cats/train\")\n",
    "categories=[]\n",
    "for f_name in filenames:\n",
    "    category=f_name.split('.')[0]\n",
    "    if category=='dog':\n",
    "        categories.append(1)\n",
    "    else:\n",
    "        categories.append(0)\n",
    "df=pd.DataFrame({\n",
    "    'filename':filenames,\n",
    "    'category':categories\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "286c7fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D,MaxPooling2D,\\\n",
    "     Dropout,Flatten,Dense,Activation,\\\n",
    "     BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "303515e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32,(3,3),activation='relu',input_shape=(Image_Width,Image_Height,Image_Channels)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64,(3,3),activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(128,(3,3),activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512,activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(2,activation='softmax'))\n",
    "\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',optimizer='rmsprop',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "88a4c53f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 126, 126, 32)      896       \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 126, 126, 32)      128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 63, 63, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 63, 63, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 61, 61, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 61, 61, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 28, 28, 128)       73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 28, 28, 128)       512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               12845568  \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 1026      \n",
      "=================================================================\n",
      "Total params: 12,942,786\n",
      "Trainable params: 12,941,314\n",
      "Non-trainable params: 1,472\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc634114",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "earlystop = EarlyStopping(patience = 10)\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor = 'val_acc',patience = 2,verbose = 1,factor = 0.5,min_lr = 0.00001)\n",
    "callbacks = [earlystop,learning_rate_reduction]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4e71768b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"category\"] = df[\"category\"].replace({0:'cat',1:'dog'})\n",
    "train_df,validate_df = train_test_split(df,test_size=0.20,random_state=42)\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "validate_df = validate_df.reset_index(drop=True)\n",
    "total_train=train_df.shape[0]\n",
    "total_validate=validate_df.shape[0]\n",
    "batch_size=15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b8ad0074",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20000 validated image filenames belonging to 2 classes.\n",
      "Found 5000 validated image filenames belonging to 2 classes.\n",
      "Found 0 validated image filenames belonging to 0 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(rotation_range=15,\n",
    "                                rescale=1./255,\n",
    "                                shear_range=0.1,\n",
    "                                zoom_range=0.2,\n",
    "                                horizontal_flip=True,\n",
    "                                width_shift_range=0.1,\n",
    "                                height_shift_range=0.1\n",
    "                                )\n",
    "\n",
    "train_generator = train_datagen.flow_from_dataframe(train_df,\n",
    "                                                 \"Resources/dogs-vs-cats/train/\",x_col='filename',y_col='category',\n",
    "                                                 target_size=Image_Size,\n",
    "                                                 class_mode='categorical',\n",
    "                                                 batch_size=batch_size)\n",
    "\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "validation_generator = validation_datagen.flow_from_dataframe(\n",
    "    validate_df, \n",
    "    \"Resources/dogs-vs-cats/train/\", \n",
    "    x_col='filename',\n",
    "    y_col='category',\n",
    "    target_size=Image_Size,\n",
    "    class_mode='categorical',\n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(rotation_range=15,\n",
    "                                rescale=1./255,\n",
    "                                shear_range=0.1,\n",
    "                                zoom_range=0.2,\n",
    "                                horizontal_flip=True,\n",
    "                                width_shift_range=0.1,\n",
    "                                height_shift_range=0.1)\n",
    "\n",
    "test_generator = train_datagen.flow_from_dataframe(train_df,\n",
    "                                                 \"Resources/dogs-vs-cats/test1\",x_col='filename',y_col='category',\n",
    "                                                 target_size=Image_Size,\n",
    "                                                 class_mode='categorical',\n",
    "                                                 batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac8d26c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/abhilashkollikonda/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1333/1333 [==============================] - 371s 278ms/step - loss: 0.6866 - accuracy: 0.6431 - val_loss: 0.6784 - val_accuracy: 0.6561\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "Epoch 2/10\n",
      "1333/1333 [==============================] - 355s 266ms/step - loss: 0.5446 - accuracy: 0.7315 - val_loss: 0.4761 - val_accuracy: 0.7808\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "Epoch 3/10\n",
      "1333/1333 [==============================] - 394s 296ms/step - loss: 0.4930 - accuracy: 0.7697 - val_loss: 0.4757 - val_accuracy: 0.7846\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "Epoch 4/10\n",
      "1333/1333 [==============================] - 417s 313ms/step - loss: 0.4601 - accuracy: 0.7869 - val_loss: 0.5631 - val_accuracy: 0.7247\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "Epoch 5/10\n",
      "1333/1333 [==============================] - 410s 308ms/step - loss: 0.4299 - accuracy: 0.8039 - val_loss: 0.3811 - val_accuracy: 0.8318\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "Epoch 6/10\n",
      "1333/1333 [==============================] - 366s 275ms/step - loss: 0.4122 - accuracy: 0.8161 - val_loss: 0.3364 - val_accuracy: 0.8609\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "Epoch 7/10\n",
      "1333/1333 [==============================] - 376s 282ms/step - loss: 0.3904 - accuracy: 0.8283 - val_loss: 0.3533 - val_accuracy: 0.8533\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "Epoch 8/10\n",
      "1198/1333 [=========================>....] - ETA: 36s - loss: 0.3873 - accuracy: 0.8306"
     ]
    }
   ],
   "source": [
    "epochs=10\n",
    "history = model.fit_generator(\n",
    "    train_generator, \n",
    "    epochs=epochs,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=total_validate//batch_size,\n",
    "    steps_per_epoch=total_train//batch_size,\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb7bc7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"model1_catsVSdogs_10epoch.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a50ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_filenames = os.listdir(\"Resources/dogs-vs-cats/test1\")\n",
    "test_df = pd.DataFrame({\n",
    "    'filename': test_filenames\n",
    "})\n",
    "nb_samples = test_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ccee460",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = model.predict_generator(test_generator, steps=np.ceil(nb_samples/batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8bda194",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['category'] = np.argmax(predict, axis=-1)\n",
    "\n",
    "label_map = dict((v,k) for k,v in train_generator.class_indices.items())\n",
    "test_df['category'] = test_df['category'].replace(label_map)\n",
    "\n",
    "test_df['category'] = test_df['category'].replace({ 'dog': 1, 'cat': 0 })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "000f23c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_test = test_df.head(18)\n",
    "sample_test.head()\n",
    "plt.figure(figsize=(12, 24))\n",
    "for index, row in sample_test.iterrows():\n",
    "    filename = row['filename']\n",
    "    category = row['category']\n",
    "    img = load_img(\"Resources/dogs-vs-cats/test1/\"+filename, target_size=Image_Size)\n",
    "    plt.subplot(6, 3, index+1)\n",
    "    plt.imshow(img)\n",
    "    plt.xlabel(filename + '(' + \"{}\".format(category) + ')' )\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
